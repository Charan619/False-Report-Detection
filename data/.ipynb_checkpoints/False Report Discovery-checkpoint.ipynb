{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_fwf('data_doctor_truthful.txt', header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "import itertools\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_gpu'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-e6477ada394a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow_gpu\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_gpu'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, Embedding, Input, RepeatVector\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scikitplot.plotters as skplt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dr. Aboolian and his staff went above and beyo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We moved from California and landed in Calgary...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Can't really add anything new to what's alread...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dr. Greyvenstein is awesome.  He delivered our...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>He is so awsome!! I was by chance I found him ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0    1    2    3    4    5  \\\n",
       "0  Dr. Aboolian and his staff went above and beyo...  NaN  NaN  NaN  NaN  NaN   \n",
       "1  We moved from California and landed in Calgary...  NaN  NaN  NaN  NaN  NaN   \n",
       "2  Can't really add anything new to what's alread...  NaN  NaN  NaN  NaN  NaN   \n",
       "3  Dr. Greyvenstein is awesome.  He delivered our...  NaN  NaN  NaN  NaN  NaN   \n",
       "4  He is so awsome!! I was by chance I found him ...  NaN  NaN  NaN  NaN  NaN   \n",
       "\n",
       "     6  \n",
       "0  NaN  \n",
       "1  NaN  \n",
       "2  NaN  \n",
       "3  NaN  \n",
       "4  NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      Dr. Aboolian and his staff went above and beyo...\n",
      "1      We moved from California and landed in Calgary...\n",
      "2      Can't really add anything new to what's alread...\n",
      "3      Dr. Greyvenstein is awesome.  He delivered our...\n",
      "4      He is so awsome!! I was by chance I found him ...\n",
      "                             ...                        \n",
      "195    Dr. Greyvenstein is by far the best physician ...\n",
      "196    Dr. Greyvenstein is an amazing Dr. He is not o...\n",
      "197    I have been going to Dr. G for the past 2.5yrs...\n",
      "198    Dr.Greyvenstein just delivered our third child...\n",
      "199    I LOVE Dr G. After moving to Clagary and findi...\n",
      "Name: 0, Length: 200, dtype: object\n",
      "                                                     0  1    2    3    4    5  \\\n",
      "0    Dr. Aboolian and his staff went above and beyo...  1  NaN  NaN  NaN  NaN   \n",
      "1    We moved from California and landed in Calgary...  1  NaN  NaN  NaN  NaN   \n",
      "2    Can't really add anything new to what's alread...  1  NaN  NaN  NaN  NaN   \n",
      "3    Dr. Greyvenstein is awesome.  He delivered our...  1  NaN  NaN  NaN  NaN   \n",
      "4    He is so awsome!! I was by chance I found him ...  1  NaN  NaN  NaN  NaN   \n",
      "..                                                 ... ..  ...  ...  ...  ...   \n",
      "195  Dr. Greyvenstein is by far the best physician ...  1  NaN  NaN  NaN  NaN   \n",
      "196  Dr. Greyvenstein is an amazing Dr. He is not o...  1  NaN  NaN  NaN  NaN   \n",
      "197  I have been going to Dr. G for the past 2.5yrs...  1  NaN  NaN  NaN  NaN   \n",
      "198  Dr.Greyvenstein just delivered our third child...  1  NaN  NaN  NaN  NaN   \n",
      "199  I LOVE Dr G. After moving to Clagary and findi...  1  NaN  NaN  NaN  NaN   \n",
      "\n",
      "       6  \n",
      "0    NaN  \n",
      "1    NaN  \n",
      "2    NaN  \n",
      "3    NaN  \n",
      "4    NaN  \n",
      "..   ...  \n",
      "195  NaN  \n",
      "196  NaN  \n",
      "197  NaN  \n",
      "198  NaN  \n",
      "199  NaN  \n",
      "\n",
      "[200 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df1[0])\n",
    "df1[1]=1\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    0   1    2    3    4   \\\n",
      "0    Doctor Aboolian is a board-certified plastic s...   0  NaN  NaN  NaN   \n",
      "1    I'll be honest, when I was first looking for d...   0  NaN  NaN  NaN   \n",
      "2    My name is Samantha. I needed to get laser hai...   0  NaN  NaN  NaN   \n",
      "3    I recently visited with Dr. Fernando Luna for ...   0  NaN  NaN  NaN   \n",
      "4    Dr. Fernando Luna cares about and listens to m...   0  NaN  NaN  NaN   \n",
      "..                                                 ...  ..  ...  ...  ...   \n",
      "351  Dr Greyvenstein was able to see me as a same d...   0  NaN  NaN  NaN   \n",
      "352  After going through a series of health related...   0  NaN  NaN  NaN   \n",
      "353  Doctor Ernst Greyvenstein is an amazing physic...   0  NaN  NaN  NaN   \n",
      "354  Dr.Greyvenstein's practice is at Circle Medica...   0  NaN  NaN  NaN   \n",
      "355  After having twins, my varicose veins were rea...   0  NaN  NaN  NaN   \n",
      "\n",
      "      5    6    7    8    9   ...   84   85   86   87   88   89   90   91  \\\n",
      "0    NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
      "1    NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
      "2    NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
      "3    NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
      "4    NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
      "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "351  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
      "352  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
      "353  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
      "354  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
      "355  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
      "\n",
      "      92   93  \n",
      "0    NaN  NaN  \n",
      "1    NaN  NaN  \n",
      "2    NaN  NaN  \n",
      "3    NaN  NaN  \n",
      "4    NaN  NaN  \n",
      "..   ...  ...  \n",
      "351  NaN  NaN  \n",
      "352  NaN  NaN  \n",
      "353  NaN  NaN  \n",
      "354  NaN  NaN  \n",
      "355  NaN  NaN  \n",
      "\n",
      "[356 rows x 94 columns]\n"
     ]
    }
   ],
   "source": [
    "df2= pd.read_fwf('data_doctor_deceptive.txt', header=None)\n",
    "df2[1]=0\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [df1, df2]\n",
    "\n",
    "df = pd.concat(frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.iloc[:, 2:94], inplace = True, axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     0  1\n",
      "0    Dr. Aboolian and his staff went above and beyo...  1\n",
      "1    We moved from California and landed in Calgary...  1\n",
      "2    Can't really add anything new to what's alread...  1\n",
      "3    Dr. Greyvenstein is awesome.  He delivered our...  1\n",
      "4    He is so awsome!! I was by chance I found him ...  1\n",
      "..                                                 ... ..\n",
      "351  Dr Greyvenstein was able to see me as a same d...  0\n",
      "352  After going through a series of health related...  0\n",
      "353  Doctor Ernst Greyvenstein is an amazing physic...  0\n",
      "354  Dr.Greyvenstein's practice is at Circle Medica...  0\n",
      "355  After having twins, my varicose veins were rea...  0\n",
      "\n",
      "[556 rows x 2 columns]\n",
      "0      1\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      1\n",
      "      ..\n",
      "351    0\n",
      "352    0\n",
      "353    0\n",
      "354    0\n",
      "355    0\n",
      "Name: 1, Length: 556, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df)\n",
    "y=df[1]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[0], y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dr'}\n",
      "False\n",
      "   10  100  101  11  12  14  15  150  16  17  ...  yearly  years  yelling  \\\n",
      "0   0    0    0   0   0   0   0    0   0   0  ...       0      0        0   \n",
      "1   0    0    0   0   0   0   0    0   0   0  ...       0      1        0   \n",
      "2   0    0    0   0   0   0   0    0   0   0  ...       0      0        0   \n",
      "3   0    0    0   0   0   0   0    0   0   0  ...       0      0        0   \n",
      "4   0    0    0   0   0   1   0    0   0   0  ...       0      1        0   \n",
      "\n",
      "   yes  young  younger  youngest  youth  youthful  yrs  \n",
      "0    0      0        0         0      0         0    0  \n",
      "1    0      0        0         0      0         0    0  \n",
      "2    0      0        0         0      0         0    0  \n",
      "3    0      0        0         0      0         0    0  \n",
      "4    0      0        0         0      0         0    0  \n",
      "\n",
      "[5 rows x 2969 columns]\n",
      "    10  100  101   11   12        14   15  150   16   17  ...  yearly  \\\n",
      "0  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  ...     0.0   \n",
      "1  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  ...     0.0   \n",
      "2  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  ...     0.0   \n",
      "3  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  ...     0.0   \n",
      "4  0.0  0.0  0.0  0.0  0.0  0.159169  0.0  0.0  0.0  0.0  ...     0.0   \n",
      "\n",
      "      years  yelling  yes  young  younger  youngest  youth  youthful  yrs  \n",
      "0  0.000000      0.0  0.0    0.0      0.0       0.0    0.0       0.0  0.0  \n",
      "1  0.053859      0.0  0.0    0.0      0.0       0.0    0.0       0.0  0.0  \n",
      "2  0.000000      0.0  0.0    0.0      0.0       0.0    0.0       0.0  0.0  \n",
      "3  0.000000      0.0  0.0    0.0      0.0       0.0    0.0       0.0  0.0  \n",
      "4  0.065546      0.0  0.0    0.0      0.0       0.0    0.0       0.0  0.0  \n",
      "\n",
      "[5 rows x 2968 columns]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the `count_vectorizer` \n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "# Fit and transform the training data \n",
    "count_train = count_vectorizer.fit_transform(X_train)                  # Learn the vocabulary dictionary and return term-document matrix.\n",
    "\n",
    "# Transform the test set \n",
    "count_test = count_vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize the `tfidf_vectorizer` \n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)    # This removes words which appear in more than 70% of the articles\n",
    "\n",
    "# Fit and transform the training data \n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train) \n",
    "\n",
    "# Transform the test set \n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Get the feature names of `tfidf_vectorizer` \n",
    "#print(tfidf_vectorizer.get_feature_names()[-10:])\n",
    "\n",
    "# Get the feature names of `count_vectorizer` \n",
    "#print(count_vectorizer.get_feature_names()[:10])\n",
    "\n",
    "count_df = pd.DataFrame(count_train.A, columns=count_vectorizer.get_feature_names())\n",
    "\n",
    "tfidf_df = pd.DataFrame(tfidf_train.A, columns=tfidf_vectorizer.get_feature_names())\n",
    "\n",
    "difference = set(count_df.columns) - set(tfidf_df.columns)\n",
    "\n",
    "print(difference)\n",
    "\n",
    "# Check whether the DataFrames are equal\n",
    "print(count_df.equals(tfidf_df))\n",
    "\n",
    "print(count_df.head())\n",
    "\n",
    "print(tfidf_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.663\n",
      "[[119   0]\n",
      " [ 62   3]]\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB() \n",
    "\n",
    "clf.fit(tfidf_train, y_train)                       # Fit Naive Bayes classifier according to X, y\n",
    "\n",
    "pred = clf.predict(tfidf_test)                     # Perform classification on an array of test vectors X.\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "cm = metrics.confusion_matrix(y_test, pred)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.804\n",
      "[[112   7]\n",
      " [ 29  36]]\n"
     ]
    }
   ],
   "source": [
    "clf.fit(count_train, y_train)\n",
    "\n",
    "pred = clf.predict(count_test)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    '''Neural network with 3 hidden layers'''\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_dim=300, activation='relu', kernel_initializer='normal'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(256, activation='relu', kernel_initializer='normal'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(80, activation='relu', kernel_initializer='normal'))\n",
    "    model.add(Dense(2, activation=\"softmax\", kernel_initializer='normal'))\n",
    "\n",
    "    # gradient descent\n",
    "    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    \n",
    "    # configure the learning process of the model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gputest",
   "language": "python",
   "name": "gputest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
